{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","from pyspark import SparkContext, SparkConf\n","from pyspark.sql import SparkSession, functions as F\n","from pyspark.sql.types import ArrayType, FloatType, IntegerType\n","from pyspark.ml.clustering import KMeans\n","from pyspark.ml import Pipeline\n","from pyspark.ml.feature import VectorAssembler, PCA\n","\n","import io\n","from PIL import Image\n","import cv2 as cv\n","\n","local = False\n","write_data = True\n","\n","import os\n","\n","os.environ[\n","    'PYSPARK_SUBMIT_ARGS'] = '--packages com.amazonaws:aws-java-sdk:1.12.230,org.apache.hadoop:hadoop-aws:3.3.1 pyspark-shell'\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["spark = SparkSession.builder.master('local').appName(\n","    'FruitsPreProc').getOrCreate()\n","#.config(\n","#\"spark.hadoop.fs.s3a.aws.credentials.provider\",\n","#\"com.amazonaws.auth.profile.ProfileCredentialsProvider\").config(\n","#'spark.hadoop.fs.s3a.impl', 'org.apache.hadoop.fs.s3a.S3AFileSystem')\n","\n","sc = spark.sparkContext\n","\n","sc._jsc.hadoopConfiguration().set('fs.s3a.impl',\n","                                  'org.apache.hadoop.fs.s3a.S3AFileSystem')\n","sc._jsc.hadoopConfiguration().set(\n","    \"fs.s3a.aws.credentials.provider\",\n","    \"com.amazonaws.auth.profile.ProfileCredentialsProvider\")\n","sc._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\",\n","                                  \"s3.eu-west-3.amazonaws.com\")\n","\n","spark.sparkContext._conf.getAll()\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if local is True:\n","    path = './fruits-360_dataset/fruits-360/Training/'\n","else:\n","    path = 's3a://stockp8oc/fruits-360/LightTrain/'\n","    # 's3a://stockp8oc/fruits-360/Training/'\n","\n","\n","def load_img_data(path=path):\n","    ImgData = spark.read.format('binaryFile') \\\n","                    .option('pathGlobFilter', '*.jpg') \\\n","                    .option('recursiveFileLookup', 'true') \\\n","                    .load(path) \\\n","                    .select('path', 'content')\n","    ImgData = ImgData.withColumn('label',\n","                                 F.element_at(F.split(F.col('path'), '/'), -2))\n","    if local is True:\n","        ImgData = ImgData.withColumn(\n","            'TruePath', F.element_at(F.split(F.col('path'), ':'), 2))\n","    else:\n","        ImgData = ImgData.withColumn('TruePath', F.col('path'))\n","\n","    ImgData = ImgData.withColumn(\n","        'imgName',\n","        F.concat('label', F.lit('_'),\n","                 F.element_at(F.split(F.col('path'), '/'), -1)))\n","    ImgData = ImgData.drop('path')\n","    return ImgData\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ImgData = load_img_data()\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_desc(content):\n","    img = np.array(Image.open(io.BytesIO(content)))\n","    orb = cv.ORB_create(nfeatures=100)\n","    keypoints_orb, desc = orb.detectAndCompute(img, None)\n","    if desc is None:\n","        desc = [np.array(32 * [0]).astype(np.float64).tolist()]\n","    else:\n","        desc = desc.astype(np.float64).tolist()\n","    return desc\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["udf_image = F.udf(\n","    get_desc,\n","    ArrayType(ArrayType(FloatType(), containsNull=False), containsNull=False))\n","\n","ImgDesc = ImgData.withColumn(\"descriptors\", F.explode(udf_image(\"content\")))\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["kmean = KMeans(k=1000, featuresCol='descriptors', seed=0)\n","model = kmean.fit(ImgDesc)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Pred = model.transform(ImgDesc)\n","Pred.show(3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ImgPred = Pred.groupBy('label', 'prediction').count()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["BoVW = ImgPred.groupBy('label').pivot('prediction').sum('count').fillna(0)\n","BoVW.show()\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["VA = VectorAssembler(inputCols=BoVW.drop('label').columns,\n","                     outputCol='features')\n","pca = PCA(k=100, inputCol='features', outputCol='pca_features')\n","pipe = Pipeline(stages=[VA, pca])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pipePCA = pipe.fit(BoVW)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pcaData = pipePCA.transform(BoVW)\n","pcaDataDF = pcaData.select(['label', 'pca_features']).toPandas()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pcaDataDFClean = pcaDataDF.join(\n","    pd.DataFrame(\n","        pcaDataDF['pca_features'].tolist())).drop(columns='pca_features')\n","if write_data is True:\n","    if local is True:\n","        pcaDataDFClean.to_csv('./featuresPCA.csv', index=False)\n","    else:\n","        pcaDataDFClean.to_csv('s3://stockp8oc/featuresPCA.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4}}